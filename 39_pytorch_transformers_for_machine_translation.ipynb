{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5dd06-d5a4-466f-a753-027d7b5b5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598648b2-9973-493b-a98d-2703ec6f89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load(\"de\")\n",
    "spacy_eng = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b350f-973d-4517-973d-148364b84e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256b688-6e1b-4af2-be69-b76140987170",
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize=tekenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(tokenize=tekenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4b5ce-9472-4c03-983a-cab47a0027c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"), fields=(german, english)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c942b2-a2f2-42ea-9ace-a5416a2886df",
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbadd3d-1a64-4d83-8ebd-eacffc286e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size, \n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "        return src_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length).unsqueeze(1).exapnd(src_seq_length, N).to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length).unsqueeze(1).expand(trg_seq_length, N).to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "\n",
    "        embed_trg = self.dropout(\n",
    "             (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(self.device)\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask = src_padding_mask,\n",
    "            tgt_mask=trg_mask\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd5129-157d-41d2-8e9a-54149fc1a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the training phase\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f51c2-181f-4093-a386-7844f7971c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aae1b6-e232-4d3c-804a-97f0460b44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed41b2c-2e06-4d57-8b96-48d1c4fb9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_sie = len(english.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder-layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = english.vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a113af-5549-4365-bbd2-3be822411afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard for nice plots\n",
    "writer = SummaryWriter(\"runs/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76ace9-838d-4fd1-9b31-ee37a405ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = batch_size,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fb498-7a2a-4b72-9b9b-f89779138108",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206b736-9d33-4d53-8758-b9bee4276c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_idx = pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb873d-afab-4730-a012-a674dde4f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "# score = bleu(test_data, model, german, english, device)\n",
    "# print(f\"Bleu score {score*100:.2f}\")\n",
    "# import sys\n",
    "# sys.exit\n",
    "\n",
    "sentence = \"ein pferd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c36e9-f583-4c91-a6cd-ddbdc67a2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "        model.eval()\n",
    "        translated_sentence = translate_sentence(\n",
    "            model, sentence, german, english, device, max_length = 100\n",
    "        )\n",
    "\n",
    "        print(f\"Translated example sentence \\n {translated_sentence}\")\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_iterator):\n",
    "            inp_data, batch.src.to(device)\n",
    "            target = batch.trg.to(device)\n",
    "\n",
    "            # forward prop\n",
    "            output = model(inp_data, target[:-1])\n",
    "\n",
    "            output = output.reshape(-1, output.shape[2])\n",
    "            target = target[1:].reshape(-1)\n",
    "            optimzer.zero_grad()\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b8067-b29f-4e99-a112-3e6235283b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = bleu(test_data, model, german, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
