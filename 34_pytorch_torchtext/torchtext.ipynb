{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67335e37-80f8-441b-9edf-ed0543aa3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS:\n",
    "\n",
    "# 1. Specify how preprocessing should be done -> Fields\n",
    "# 2. Use Dataset to load the data -> TabularDataset (JSON/CSV/TSV Files)\n",
    "# 3. Construct an iterator to do batching & padding -> BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0fb09ac-7002-4292-8218-eeb543f32255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f0f6f2c-a28a-4a52-a72f-e637a2a38f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18fa74-cfc5-42da-8032-833eca3b1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [tok.text for tok in space_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67572577-73bd-486e-89e2-1e1def291020",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)\n",
    "score = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c78190-9611-4306-9e3b-0a70a43f0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'quote': ('q', quote), 'score': ('s', score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "447eb989-4c49-4acb-8993-2e01cef750fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "    path='mydata',\n",
    "    train='train.json',\n",
    "    test='test.json',\n",
    "    #validation='validation.json'\n",
    "    format='json',\n",
    "    fields=fields\n",
    ")\n",
    "\n",
    "# train_data, test_data = TabularDataset.splits(\n",
    "#     path='mydata',\n",
    "#     train='train.csv',\n",
    "#     test='test.csv',\n",
    "#     format='csv',\n",
    "#     fields=fields\n",
    "# )\n",
    "\n",
    "# train_data, test_data = TabularDataset.splits(\n",
    "#     path='mydata',\n",
    "#     train='train.tsv',\n",
    "#     test='test.tsv',\n",
    "#     format='json',\n",
    "#     fields=fields\n",
    "# )\n",
    "\n",
    "# print(train_data[0].__dict__.keys())\n",
    "# print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052cccea-284b-454a-8b9d-4054193ea46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote.build_vocab(train_data,\n",
    "                 max_size=10000,\n",
    "                 min_freq=1,\n",
    "                 vectors='glove.6B.100d') # 1 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c509e1d-04bb-4cbc-9a8d-9dc56ed85cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27, 10],\n",
      "        [29, 21],\n",
      "        [ 7,  4],\n",
      "        [26,  3],\n",
      "        [18,  6],\n",
      "        [ 2, 11],\n",
      "        [25, 17],\n",
      "        [ 1,  4],\n",
      "        [ 1,  3],\n",
      "        [ 1, 30],\n",
      "        [ 1, 28],\n",
      "        [ 1,  5],\n",
      "        [ 1, 13],\n",
      "        [ 1,  2],\n",
      "        [ 1,  9],\n",
      "        [ 1, 23]], device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "tensor([[33],\n",
      "        [19],\n",
      "        [24],\n",
      "        [14],\n",
      "        [15],\n",
      "        [34],\n",
      "        [32],\n",
      "        [31],\n",
      "        [16],\n",
      "        [20],\n",
      "        [22],\n",
      "        [12],\n",
      "        [ 5],\n",
      "        [ 8]], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size=2,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "for batch in train_iterator:\n",
    "    print(batch.q)\n",
    "    print(batch.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722c475-d0d2-4e30-807c-42b1395a2644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
