{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4f66f7-49b0-4d16-93d5-1b95f39062de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import save_checkpoint, load_checkpoint, print_examples\n",
    "from get_loader import get_loader\n",
    "from model import CNNtoRNN\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90f546e-fc53-4411-817c-604928e752e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((356, 356)),\n",
    "            transforms.RandomCrop((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_loader, dataset = get_loader(\n",
    "        root_folder=\"custom_datasets/flickr8k/images\",\n",
    "        annotation_file=\"custom_datasets/flickr8k/captions.txt\",\n",
    "        transform=transform,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True # performance boost\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    load_model = False\n",
    "    save_model = True\n",
    "\n",
    "\n",
    "    # Hyperparameters\n",
    "    embed_size = 256\n",
    "    hidden_size = 256\n",
    "    vocab_size = len(dataset.vocab)\n",
    "    num_layers = 1\n",
    "    learning_rate = 3e-4\n",
    "    num_epochs = 100\n",
    "\n",
    "    # for tensorboard\n",
    "    writer = SummaryWriter(\"runs/flickr\")\n",
    "    step = 0\n",
    "\n",
    "    # initialize model, loss, etc.\n",
    "    model = CNNtoRNN(embed_size, hidden_size, vocab_size, num_layers).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab.stoi[\"<PAD>\"])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if load_model:\n",
    "        step = load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print_examples(model, device, dataset)\n",
    "        if save_model:\n",
    "            checkpoint = {\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"step\": step,\n",
    "            }\n",
    "            save_checkpoint(checkpoint)\n",
    "\n",
    "        for idx, (imgs, captions) in enumerate(tqdm(train_loader)):\n",
    "            imgs = imgs.to(device)\n",
    "            captions = captions.to(device)\n",
    "            outputs = model(imgs, captions[:-1])\n",
    "            loss = criterion(outputs.reshape(-1, outputs.shape[2]), captions.reshape(-1))\n",
    "\n",
    "            writer.add_scalar(\"Training loss\", loss.item(), global_step=step)\n",
    "            step += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(loss)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088f8aa-62b1-4190-aae3-bbd0b530f711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 CORRECT: Dog on a beach by the ocean\n",
      "Example 1 OUTPUT: harbor observes fake cloudy form forehead forehead 23 shaggy trees harbor sparkler flight snowboarders parking old stripe electric cape making collie enjoy into harbor corn bathroom fist bounces sponsored keep sticks runway dunks reaches seashore chatting various protest aid seashore rocky paddling deep picking edge hall vertical barn orange rests\n",
      "Example 2 CORRECT: Child holding red frisbee outdoors\n",
      "Example 2 OUTPUT: seen keep skiing moment deep pumpkin closed rails observes fake cloudy paddling deep picking edge hall vertical barn orange rests parachute upturned gazes juice amusement hooded drops old cloth stripe electric cape grins cords flipping gym participate underground checkered wheeled playful sidecar gloved lunch barrier barrier main wood concerned jack\n",
      "Example 3 CORRECT: Bus driving by parked cars\n",
      "Example 3 OUTPUT: harbor sparkler flight snowboarders parking cloudy form forehead forehead 23 shaggy trees harbor sparkler flight snowboarders parking old stripe electric cape making collie enjoy into harbor corn bathroom fist bounces sponsored keep sticks runway dunks reaches seashore chatting various protest aid seashore rocky paddling deep picking edge hall vertical barn\n",
      "Example 4 CORRECT: A small boat in the ocean\n",
      "Example 4 OUTPUT: seagull descends cheerleaders motorbikes misses snowboarders parking cloudy form forehead forehead 23 shaggy trees harbor sparkler flight snowboarders parking old stripe electric cape making collie enjoy into harbor corn bathroom fist bounces sponsored keep sticks runway dunks reaches seashore chatting various protest aid seashore rocky paddling deep picking edge hall\n",
      "Example 5 CORRECT: A cowboy riding a horse in the desert\n",
      "Example 5 OUTPUT: harbor observes lies fetch young skinny beach speaking rainy crossed stone crossed see slip chased digital excited teenage curb hooded transportation 6 wrestles view overlooking dance move move truck deep picking edge garbage be image image melting view matching stands dot glacier bound kayaks parent similar lush palm sign only\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▍                                                            | 295/1265 [01:45<03:50,  4.20it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
