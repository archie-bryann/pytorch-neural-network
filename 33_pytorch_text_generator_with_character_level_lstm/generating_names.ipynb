{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51360f9a-796b-4fe0-8743-a3e3c93a65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import random\n",
    "import sys\n",
    "import unidecode\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130e1d01-7ee6-45b2-ae8d-b49c3ec6780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd05646a-2c6d-4318-85a6-1bcc5db8031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get characters from string.printable\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c9513b-6515-4eaf-a607-0e2ea9762806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read large text file (Note can be any text file: not limited to just shakespeare)\n",
    "file = unidecode.unidecode(open('data/babynames.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b900fcb9-a2b4-4656-b066-01ae0147bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embed = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embed(x)\n",
    "        out, (hidden, cell) = self.lstm(out.unsqueeze(1), (hidden, cell))\n",
    "        out = self.fc(out.reshape(out.shape[0], -1))\n",
    "        return out, (hidden, cell)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce78615-e9ff-4b21-8643-c92aca6d23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self):\n",
    "        self.chunk_len = 250\n",
    "        self.num_epochs = 5000\n",
    "        self.batch_size = 1\n",
    "        self.print_every = 50\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 2\n",
    "        self.lr = 0.003\n",
    "\n",
    "    def char_tensor(self, string):\n",
    "        tensor = torch.zeros(len(string)).long()\n",
    "        for c in range(len(string)):\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        return tensor\n",
    "\n",
    "    def get_random_batch(self):\n",
    "        start_idx = random.randint(0, len(file) - self.chunk_len)\n",
    "        end_idx = start_idx + self.chunk_len + 1\n",
    "        text_str = file[start_idx:end_idx]\n",
    "        text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
    "        text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            text_input[i,:] = self.char_tensor(text_str[:-1])\n",
    "            text_target[i,:] = self.char_tensor(text_str[1:])\n",
    "\n",
    "        return text_input.long(), text_target.long()\n",
    "\n",
    "    def generate(self, initial_str='A', prediction_len=100, temperature=0.85):\n",
    "        hidden, cell =  self.rnn.init_hidden(batch_size=self.batch_size)\n",
    "        initial_input = self.char_tensor(initial_str)\n",
    "        predicted = initial_str\n",
    "\n",
    "        for p in range(len(initial_str) - 1):\n",
    "            _, (hidden, cell) = self.rnn(initial_input[p].view(1).to(device), hidden, cell)\n",
    "            \n",
    "        last_char = initial_input[-1]\n",
    "        for p in range(prediction_len):\n",
    "            output, (hidden, cell) = self.rnn(last_char.view(1).to(device), hidden, cell)\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_char = torch.multinomial(output_dist, 1)[0]\n",
    "            predicted_char = all_characters[top_char]\n",
    "            predicted += predicted_char\n",
    "            last_char = self.char_tensor(predicted_char)\n",
    "\n",
    "        return predicted\n",
    "\n",
    "    def train(self):\n",
    "        self.rnn = RNN(n_characters, self.hidden_size, self.num_layers, n_characters).to(device)\n",
    "        optimizer = torch.optim.Adam(self.rnn.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        writer = SummaryWriter(f'runs/names0') # for tensorboard\n",
    "\n",
    "        print(\"=> Starting training\")\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            inp, target = self.get_random_batch()\n",
    "            hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
    "\n",
    "            self.rnn.zero_grad()\n",
    "            loss = 0\n",
    "            inp = inp.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            for c in range(self.chunk_len):\n",
    "                output, (hidden, cell) = self.rnn(inp[:, c], hidden, cell)\n",
    "                loss += criterion(output, target[:, c])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss.item() / self.chunk_len\n",
    "            \n",
    "            if epoch % self.print_every == 0:\n",
    "                print(f'Loss: {loss}')\n",
    "                print(self.generate())\n",
    "\n",
    "            writer.add_scalar('Training loss', loss, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add9446-c385-4d43-86d5-22fc8c50dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Starting training\n",
      "Loss: 2.429825927734375\n",
      "AfDir\n",
      "Koran\n",
      "Ketnian\n",
      "Wer\n",
      "Gicdrka\n",
      "Ferira\n",
      "Bonniddan\n",
      "gsconen\n",
      "Brlilsa\n",
      "Tarst\n",
      "vanndrdd\n",
      "Tarsil\n",
      "Anir\n",
      "inida\n",
      "San\n",
      "Loss: 2.25792333984375\n",
      "Ana\n",
      "Canke\n",
      "tanne\n",
      "JocPer\n",
      "Hina\n",
      "Dala\n",
      "Yalery\n",
      "Ginna\n",
      "Albinn\n",
      "Pathran\n",
      "Japse\n",
      "Kern\n",
      "Kale\n",
      "Natie\n",
      "Ertan\n",
      "Bd\n",
      "Elas\n",
      "Anza\n",
      "Loss: 2.1639716796875\n",
      "Anchell\n",
      "Cald\n",
      "Koron\n",
      "Daul\n",
      "Harice\n",
      "Mavin\n",
      "Mayr\n",
      "Imina\n",
      "Eledsey\n",
      "Trien\n",
      "Borlen\n",
      "Iraneg\n",
      "Cwarly\n",
      "Dartorne\n",
      "Dodren\n",
      "De\n",
      "Loss: 2.102845458984375\n",
      "Avy\n",
      "Aulan\n",
      "Albelle\n",
      "Jaune\n",
      "Mamin\n",
      "Janmol\n",
      "Jann\n",
      "En\n",
      "Lyx\n",
      "Maria\n",
      "Radron\n",
      "Luilin\n",
      "Matia\n",
      "Kayda\n",
      "Scuol\n",
      "Dolle\n",
      "Ilendett\n",
      "Loss: 1.9989727783203124\n",
      "Andra\n",
      "Anna\n",
      "Kasese\n",
      "Anton\n",
      "Dennagh\n",
      "Noran\n",
      "Ronann\n",
      "Falence\n",
      "Marord\n",
      "Melduciel\n",
      "Bestacie\n",
      "Jeonda\n",
      "Stamal\n",
      "Condenn\n",
      "\n",
      "Loss: 2.29843212890625\n",
      "Anice\n",
      "Keya\n",
      "Marylopinio\n",
      "Kry\n",
      "Patris\n",
      "Dady\n",
      "Kristina\n",
      "Kerioberte\n",
      "Crattey\n",
      "Angey\n",
      "Braci\n",
      "Dayline\n",
      "Harrenetta\n",
      "Dia\n",
      "Loss: 2.24019384765625\n",
      "Agmine\n",
      "Danitta\n",
      "Clistelline\n",
      "Kenne\n",
      "Ricella\n",
      "Angelia\n",
      "Iseane\n",
      "Leonetta\n",
      "Kriston\n",
      "Adissa\n",
      "Mily\n",
      "Stebetk\n",
      "huis\n",
      "Pat\n",
      "Loss: 1.8133515625\n",
      "Alia\n",
      "Jeanna\n",
      "Karia\n",
      "Tedine\n",
      "Jathery\n",
      "Jathiolipa\n",
      "Dari\n",
      "Shabrah\n",
      "Dalir\n",
      "Kathan\n",
      "Lena\n",
      "Ady\n",
      "Race\n",
      "Payla\n",
      "Janis\n",
      "Elori\n",
      "Loss: 1.8755418701171875\n",
      "Angaria\n",
      "Rona\n",
      "Doris\n",
      "Frandia\n",
      "Jobin\n",
      "Horeta\n",
      "Tosel\n",
      "Rebeyla\n",
      "Lynna\n",
      "Ronen\n",
      "Devie\n",
      "Toberta\n",
      "Aley\n",
      "Meristin\n",
      "Edder\n",
      "R\n",
      "Loss: 1.5832158203125\n",
      "Adi\n",
      "Kenman\n",
      "Frian\n",
      "Rannalina\n",
      "Julis\n",
      "Ebbion\n",
      "Kathi\n",
      "Rosena\n",
      "Rolale\n",
      "Roderine\n",
      "Fenarda\n",
      "Cailen\n",
      "Rosan\n",
      "Fanoren\n",
      "Lar\n",
      "Loss: 1.735985595703125\n",
      "Ammery\n",
      "Annalyn\n",
      "Olynne\n",
      "Avany\n",
      "Tammyonna\n",
      "Margarion\n",
      "Sherry\n",
      "Donnarett\n",
      "Samberlla\n",
      "Suzanne\n",
      "Bernon\n",
      "Jerriel\n",
      "Don\n",
      "Loss: 2.356362060546875\n",
      "Acias\n",
      "Shan\n",
      "Dudis\n",
      "Armarion\n",
      "Camilea\n",
      "Dharilie\n",
      "Layson\n",
      "Tophy\n",
      "Davin\n",
      "Yselio\n",
      "Donoy\n",
      "Karlen\n",
      "Dario\n",
      "Meghanda\n",
      "Ahlb\n",
      "Loss: 1.6671695556640624\n",
      "Argie\n",
      "Jeannya\n",
      "Maryn\n",
      "Aiguston\n",
      "Jenzie\n",
      "Maria\n",
      "Maelery\n",
      "Isanne\n",
      "Ario\n",
      "Trank\n",
      "Ludio\n",
      "Gus\n",
      "Mickici\n",
      "Adalyn\n",
      "Matelian\n",
      "Loss: 1.3468494873046875\n",
      "Asten\n",
      "Ginzette\n",
      "Delie\n",
      "Lera\n",
      "Natalyn\n",
      "Victorie\n",
      "Meliston\n",
      "Kriston\n",
      "Marica\n",
      "Emerina\n",
      "Glerdon\n",
      "Rona\n",
      "Dela\n",
      "Bernivi\n",
      "\n",
      "Loss: 1.5505697021484375\n",
      "Anna\n",
      "Jane\n",
      "Roson\n",
      "Tore\n",
      "Wille\n",
      "Leila\n",
      "Bryan\n",
      "Nathabel\n",
      "Nancie\n",
      "Carley\n",
      "Tobin\n",
      "Trean\n",
      "Lai\n",
      "Elisa\n",
      "Eliste\n",
      "Damia\n",
      "Jayl\n",
      "Loss: 1.79925\n",
      "Arai\n",
      "Conner\n",
      "Erico\n",
      "Annah\n",
      "Alithana\n",
      "Elia\n",
      "Nadin\n",
      "Georna\n",
      "Eli\n",
      "Rhean\n",
      "Jea\n",
      "Paul\n",
      "Tatishol\n",
      "Christio\n",
      "Rexegine\n",
      "Jose\n",
      "Loss: 1.9206881103515625\n",
      "Andisha\n",
      "Tanyonna\n",
      "frista\n",
      "Baudette\n",
      "Leona\n",
      "Frodi\n",
      "Kristin\n",
      "Orindo\n",
      "Angela\n",
      "Randio\n",
      "Kali\n",
      "Toni\n",
      "Ivia\n",
      "Jabell\n",
      "Monja\n",
      "Loss: 1.885319580078125\n",
      "Adeth\n",
      "Helon\n",
      "Brodrenc\n",
      "Darrie\n",
      "Arolanne\n",
      "Adel\n",
      "Alice\n",
      "Aris\n",
      "Allio\n",
      "Emilia\n",
      "Ashley\n",
      "Dinna\n",
      "Gerger\n",
      "Alisea\n",
      "Rooperd\n",
      "\n",
      "Loss: 1.8186331787109375\n",
      "Asha\n",
      "Yulzis\n",
      "Cathye\n",
      "Briddy\n",
      "Bristina\n",
      "Treemi\n",
      "olliana\n",
      "Adal\n",
      "Janie\n",
      "Cary\n",
      "Tami\n",
      "Maithan\n",
      "Santhonor\n",
      "Mausha\n",
      "Neaa\n",
      "\n",
      "Loss: 1.499169189453125\n",
      "Ann\n",
      "Lorenzor\n",
      "Adrien\n",
      "Lynda\n",
      "Loren\n",
      "Bracie\n",
      "Elan\n",
      "Ashlyn\n",
      "Bryssid\n",
      "Josen\n",
      "Liam\n",
      "Louie\n",
      "Phyllie\n",
      "Chelin\n",
      "Karlai\n",
      "Let\n",
      "Loss: 1.49578564453125\n",
      "Aprie\n",
      "Frederitin\n",
      "Conetth\n",
      "Jacque\n",
      "Shante\n",
      "Lance\n",
      "Lylas\n",
      "Patrina\n",
      "Landy\n",
      "Lane\n",
      "Loren\n",
      "Rexynne\n",
      "Stevia\n",
      "Roselia\n",
      "Ri\n",
      "Loss: 1.6965428466796875\n",
      "Agie\n",
      "Jasson\n",
      "Juanita\n",
      "Charis\n",
      "Joonattan\n",
      "Fayne\n",
      "Willie\n",
      "Ivette\n",
      "Bentin\n",
      "Carice\n",
      "Ericia\n",
      "Adrianna\n",
      "Vernan\n",
      "Isayana\n",
      "Loss: 1.43186376953125\n",
      "Alen\n",
      "Sherry\n",
      "Sharon\n",
      "Anallis\n",
      "Arvin\n",
      "Adelia\n",
      "Betty\n",
      "Emma\n",
      "Diemanna\n",
      "Dale\n",
      "Cristine\n",
      "Dommy\n",
      "Kande\n",
      "Luis\n",
      "Stazara\n",
      "Ta\n",
      "Loss: 1.59534912109375\n",
      "Andra\n",
      "Evavon\n",
      "Babi\n",
      "Kendrey\n",
      "Madison\n",
      "Miguel\n",
      "Louit\n",
      "Martin\n",
      "Nany\n",
      "Christopher\n",
      "Jamiso\n",
      "Jenny\n",
      "Jack\n",
      "Joan\n",
      "Kyan\n",
      "Ly\n",
      "Loss: 1.310488525390625\n",
      "Angelia\n",
      "Adisha\n",
      "Ariel\n",
      "Arabella\n",
      "Aliana\n",
      "Alexie\n",
      "Marion\n",
      "Earnie\n",
      "Alanna\n",
      "Annita\n",
      "Auraine\n",
      "Adalen\n",
      "Amelia\n",
      "Adriann\n",
      "Loss: 1.4661923828125\n",
      "Andren\n",
      "Eddie\n",
      "Giegan\n",
      "Garrette\n",
      "Fredette\n",
      "Hayla\n",
      "Jashe\n",
      "Hailey\n",
      "Kennya\n",
      "Kellie\n",
      "Kathyr\n",
      "Leiland\n",
      "Savanna\n",
      "Serrand\n",
      "Loss: 1.5388961181640626\n",
      "Allen\n",
      "Jumina\n",
      "Alike\n",
      "Amarina\n",
      "Amesha\n",
      "Bett\n",
      "Fredan\n",
      "Laury\n",
      "Luisann\n",
      "Monja\n",
      "Makanda\n",
      "Kemy\n",
      "Melsie\n",
      "Marion\n",
      "Melvin\n",
      "M\n",
      "Loss: 1.4861612548828125\n",
      "Aagusa\n",
      "Annie\n",
      "Axton\n",
      "Charlus\n",
      "Christina\n",
      "Collina\n",
      "Jaydon\n",
      "Chaden\n",
      "Elisabeth\n",
      "Anda\n",
      "Blake\n",
      "Christina\n",
      "Elena\n",
      "Janet\n",
      "Loss: 1.54937890625\n",
      "Altan\n",
      "Ashlyn\n",
      "Sheryle\n",
      "Cathuel\n",
      "Margare\n",
      "Noeller\n",
      "Sereck\n",
      "Stephie\n",
      "Sherry\n",
      "Scylfond\n",
      "Sechan\n",
      "Samuel\n",
      "Simon\n",
      "Sylis\n",
      "Loss: 1.8828150634765626\n",
      "Abian\n",
      "Ameli\n",
      "Danell\n",
      "Phillip\n",
      "Bettie\n",
      "Beckie\n",
      "Bone\n",
      "Brael\n",
      "Bryant\n",
      "Cathony\n",
      "Claylene\n",
      "Calevie\n",
      "Cora\n",
      "Graylie\n",
      "Prys\n",
      "Loss: 1.56862353515625\n",
      "Arton\n",
      "Analia\n",
      "Anna\n",
      "Annie\n",
      "Brynna\n",
      "Ashla\n",
      "Andrien\n",
      "Kyla\n",
      "Shaun\n",
      "Sharrett\n",
      "Siloberto\n",
      "Samuel\n",
      "Randal\n",
      "Taylo\n",
      "Vermin\n",
      "Loss: 1.444341064453125\n",
      "Alena\n",
      "Allan\n",
      "Arvianna\n",
      "Alan\n",
      "Ella\n",
      "Gabry\n",
      "Isabeltha\n",
      "Izabella\n",
      "Cam\n",
      "Corterbell\n",
      "Devan\n",
      "Denisa\n",
      "Jellie\n",
      "Kelly\n",
      "Laur\n",
      "Loss: 1.3992481689453125\n",
      "Ale\n",
      "Abil\n",
      "Cora\n",
      "Camila\n",
      "Carolyn\n",
      "Fredalle\n",
      "James\n",
      "Guy\n",
      "Katherine\n",
      "Lasha\n",
      "Lynn\n",
      "Marvin\n",
      "Nicole\n",
      "Natalie\n",
      "Suzette\n",
      "Lu\n",
      "Loss: 1.27957470703125\n",
      "Aurelie\n",
      "Laris\n",
      "Mindy\n",
      "Payley\n",
      "Ralph\n",
      "Ronald\n",
      "Vernon\n",
      "Ariell\n",
      "Sheila\n",
      "Josue\n",
      "Brian\n",
      "Claudie\n",
      "Berny\n",
      "Kaylee\n",
      "Roban\n",
      "K\n",
      "Loss: 1.4259718017578125\n",
      "Amelie\n",
      "halvin\n",
      "Loryn\n",
      "Lacee\n",
      "Laura\n",
      "Lori\n",
      "Leeanno\n",
      "Leslyn\n",
      "Lola\n",
      "Laura\n",
      "Fayla\n",
      "Jackie\n",
      "Jeesonso\n",
      "Jaylyn\n",
      "Jaden\n",
      "Jan\n",
      "Loss: 1.5730899658203126\n",
      "Aleber\n",
      "Lynn\n",
      "Lee\n",
      "Merlynn\n",
      "Mon\n",
      "Myra\n",
      "Manuel\n",
      "Marton\n",
      "Sakai\n",
      "Someria\n",
      "Soloisea\n",
      "Audrian\n",
      "Amie\n",
      "Amishia\n",
      "Annah\n",
      "Aron\n",
      "Loss: 1.2682772216796876\n",
      "Aquelo\n",
      "Brock\n",
      "Hiath\n",
      "Keyana\n",
      "Lucia\n",
      "Myrti\n",
      "Melandre\n",
      "Mona\n",
      "Miland\n",
      "Manel\n",
      "Marie\n",
      "Marisol\n",
      "Mike\n",
      "Murtis\n",
      "Marla\n",
      "Nyto\n",
      "Loss: 1.4868077392578125\n",
      "Arelyn\n",
      "Caylee\n",
      "Corrina\n",
      "Diana\n",
      "Toby\n",
      "Aourus\n",
      "Clare\n",
      "Eileen\n",
      "Lakey\n",
      "Matthew\n",
      "Moriah\n",
      "Penelope\n",
      "Rick\n",
      "Sathan\n",
      "Shanel\n",
      "Loss: 1.268528076171875\n",
      "Aeline\n",
      "Ezarton\n",
      "Joseph\n",
      "Juniol\n",
      "Tasha\n",
      "Alexia\n",
      "Anthon\n",
      "Chasey\n",
      "Celesto\n",
      "Carlette\n",
      "Carmela\n",
      "Dona\n",
      "Euouston\n",
      "Fanice\n",
      "Loss: 1.0566458740234375\n",
      "Acelle\n",
      "Auguen\n",
      "Anthoni\n",
      "Alisa\n",
      "Alyson\n",
      "Alex\n",
      "Abigayana\n",
      "Angel\n",
      "Alexon\n",
      "Armin\n",
      "Allison\n",
      "Alexi\n",
      "Angela\n",
      "Amiyah\n",
      "Anto\n",
      "Loss: 1.580097412109375\n",
      "Anguette\n",
      "Briance\n",
      "Joseph\n",
      "Emmy\n",
      "Mercy\n",
      "Teresa\n",
      "Alyson\n",
      "Arianette\n",
      "Alina\n",
      "Ariell\n",
      "Arietta\n",
      "Annrey\n",
      "Brett\n",
      "Beatris\n",
      "\n",
      "Loss: 1.8361529541015624\n",
      "Art\n",
      "Analisa\n",
      "Ann\n",
      "Quinton\n",
      "Arley\n",
      "Artn\n",
      "Brittria\n",
      "Caroline\n",
      "Candel\n",
      "Susanna\n",
      "Sier\n",
      "Stephani\n",
      "Jayia\n",
      "Kaeley\n",
      "Ashley\n",
      "Loss: 1.3190289306640626\n",
      "Alice\n",
      "Amanda\n",
      "Anastas\n",
      "Lyla\n",
      "Anna\n",
      "Edon\n",
      "Larrie\n",
      "Marla\n",
      "Micah\n",
      "Noelle\n",
      "Rosalie\n",
      "Renee\n",
      "Weston\n",
      "Rudenta\n",
      "Ruth\n",
      "Roger\n",
      "Loss: 1.15514697265625\n",
      "Audrey\n",
      "Arleen\n",
      "Angela\n",
      "Brendra\n",
      "Cara\n",
      "Daisha\n",
      "Ellion\n",
      "Edward\n",
      "Erik\n",
      "Harry\n",
      "Corinna\n",
      "Jovy\n",
      "Daphlea\n",
      "Marcie\n",
      "Penny\n",
      "T\n",
      "Loss: 1.4812855224609376\n",
      "Arien\n",
      "Adenna\n",
      "Ayanne\n",
      "Annette\n",
      "Antoinette\n",
      "Bernarden\n",
      "Kellie\n",
      "Bevey\n",
      "Brent\n",
      "Josie\n",
      "Maurence\n",
      "Demarios\n",
      "Morkoy\n",
      "Ph\n",
      "Loss: 1.709625244140625\n",
      "Adiley\n",
      "Byron\n",
      "Felany\n",
      "Cathy\n",
      "Marialla\n",
      "Mchelva\n",
      "Nicolas\n",
      "Nora\n",
      "Nataly\n",
      "Stuart\n",
      "Stanley\n",
      "Theodore\n",
      "Terrissa\n",
      "Alons\n",
      "Loss: 1.529086181640625\n",
      "Ang\n",
      "Warner\n",
      "George\n",
      "Elicia\n",
      "Anne\n",
      "Isabara\n",
      "Ida\n",
      "Jame\n",
      "Jackson\n",
      "Joyce\n",
      "Jences\n",
      "Jeanne\n",
      "Jeannette\n",
      "Kowert\n",
      "Lowince\n",
      "L\n",
      "Loss: 1.2970113525390625\n",
      "Alik\n",
      "Mara\n",
      "Melesa\n",
      "Eberica\n",
      "Joye\n",
      "Halle\n",
      "Johan\n",
      "Prucille\n",
      "Roland\n",
      "Loby\n",
      "Katie\n",
      "Kristen\n",
      "Lail\n",
      "Kennedy\n",
      "Kendall\n",
      "Kry\n",
      "Loss: 1.3679273681640625\n",
      "Ay\n",
      "Andere\n",
      "Aurorette\n",
      "Julian\n",
      "Alex\n",
      "Dwion\n",
      "Ethan\n",
      "Bobbie\n",
      "Gary\n",
      "Gail\n",
      "Grant\n",
      "Bonnie\n",
      "Houstavion\n",
      "Anael\n",
      "Christophe\n",
      "Loss: 1.321576904296875\n",
      "Arin\n",
      "Francisco\n",
      "Carole\n",
      "Kimberly\n",
      "Patricia\n",
      "Pearlie\n",
      "Glen\n",
      "Clarissa\n",
      "Eloise\n",
      "Herman\n",
      "Donald\n",
      "George\n",
      "Helen\n",
      "Irvin\n",
      "Loss: 1.390157958984375\n",
      "Ashlyn\n",
      "Bradson\n",
      "Bessie\n",
      "Elica\n",
      "Felianna\n",
      "Kristina\n",
      "Dallor\n",
      "Justina\n",
      "Judith\n",
      "Jason\n",
      "Jamie\n",
      "Joy\n",
      "Juan\n",
      "Joanna\n",
      "Kate\n",
      "\n",
      "Loss: 1.1452635498046875\n",
      "Arvhond\n",
      "Brianna\n",
      "Bertharo\n",
      "Bedsie\n",
      "Brad\n",
      "Carol\n",
      "Cari\n",
      "Cecilia\n",
      "Tharia\n",
      "Ellie\n",
      "Marisa\n",
      "Tara\n",
      "Tonyd\n",
      "Alfred\n",
      "Armida\n",
      "\n",
      "Loss: 1.2325694580078126\n",
      "Arsie\n",
      "Beo\n",
      "Celia\n",
      "Devon\n",
      "Dorthel\n",
      "Devin\n",
      "Juan\n",
      "Jenica\n",
      "Jennyseb\n",
      "Inanda\n",
      "Jaelinda\n",
      "Jackie\n",
      "Jonathan\n",
      "Josiah\n",
      "Jaydo\n",
      "Loss: 1.608231689453125\n",
      "Angelia\n",
      "Cheryl\n",
      "Kendall\n",
      "Roy\n",
      "Alfred\n",
      "Blane\n",
      "Josephine\n",
      "Laryn\n",
      "Theomeal\n",
      "Wina\n",
      "Alexia\n",
      "Aneddeo\n",
      "Brooklyn\n",
      "Carolyn\n",
      "Loss: 1.1748734130859375\n",
      "Anto\n",
      "Brittance\n",
      "Dana\n",
      "Karl\n",
      "Lashonda\n",
      "Viola\n",
      "Anita\n",
      "Angel\n",
      "Barra\n",
      "Blake\n",
      "Claude\n",
      "Camerone\n",
      "Elmer\n",
      "Lorenzo\n",
      "Allad\n",
      "A\n",
      "Loss: 1.0841824951171875\n",
      "Anndrea\n",
      "Sarah\n",
      "Jamie\n",
      "Jason\n",
      "Jess\n",
      "Shelley\n",
      "Shell\n",
      "Dominique\n",
      "Anthonisha\n",
      "Shanya\n",
      "Sherry\n",
      "Sumine\n",
      "Shannon\n",
      "Sarah\n",
      "\n",
      "Loss: 1.139846435546875\n",
      "Arnaldon\n",
      "Curt\n",
      "Dominic\n",
      "Claude\n",
      "Estan\n",
      "Desmond\n",
      "Frankie\n",
      "Karen\n",
      "Corey\n",
      "Fernedith\n",
      "Franklin\n",
      "Gladys\n",
      "Herbert\n",
      "Jarr\n",
      "Loss: 1.2094005126953125\n",
      "Adra\n",
      "Brinitan\n",
      "Clanda\n",
      "Danny\n",
      "Cheryl\n",
      "Donald\n",
      "Earl\n",
      "Gly\n",
      "Hale\n",
      "Eva\n",
      "George\n",
      "Haylee\n",
      "Garlene\n",
      "Giami\n",
      "Irene\n",
      "Jennifer\n",
      "Loss: 1.2836871337890625\n",
      "Angela\n",
      "Edmundo\n",
      "Evelyn\n",
      "Guopfie\n",
      "Jack\n",
      "Jackelyn\n",
      "Joelynn\n",
      "Joanna\n",
      "Kasey\n",
      "Keshawn\n",
      "Kayleigh\n",
      "Reba\n",
      "Dave\n",
      "David\n",
      "Car\n",
      "Loss: 1.4660360107421875\n",
      "Annaber\n",
      "Adrion\n",
      "Allen\n",
      "Angele\n",
      "Adrianne\n",
      "Adeline\n",
      "Adalia\n",
      "Alia\n",
      "Adeley\n",
      "Brooklyn\n",
      "Brianna\n",
      "Benmad\n",
      "Brenton\n",
      "Betty\n",
      "Loss: 1.0867886962890625\n",
      "Alexys\n",
      "Andrew\n",
      "Alton\n",
      "Aracelle\n",
      "Adela\n",
      "Ann\n",
      "Caren\n",
      "Channa\n",
      "Eanna\n",
      "Felix\n",
      "Grace\n",
      "Hailee\n",
      "Ida\n",
      "Jaeline\n",
      "Jack\n",
      "Jayme\n",
      "J\n"
     ]
    }
   ],
   "source": [
    "gennames = Generator()\n",
    "gennames.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
